# core/image_analyzer.py
import os
import argparse
import concurrent.futures
from typing import Tuple

import numpy as np

# from ..i18n import _
from PIL import Image
import logging
from typing import Optional

from resolution_suggester.config import INTERPOLATION_METHOD_UPSCALE, InterpolationMethods, QualityMetrics, \
    PSNR_IS_LARGE_AS_INF, INTERMEDIATE_DIR
from resolution_suggester.core.image_processing import get_resize_function
from resolution_suggester.ml.predictor import QuickPredictor, extract_features_of_original_img
from resolution_suggester.utils.reporters import IReporter
from .image_loader import load_image
from .metrics import compute_resolutions, calculate_metrics
from ..utils.reporting import QualityHelper, ConsoleReporter


class ImageAnalyzer:
    """
    Class encapsulating image analysis logic.
    Provides methods for analyzing individual files and file groups.
    """

    def __init__(self, args: argparse.Namespace, reporters: list[IReporter] = None):
        """
        Initializes the image analyzer.

        Args:
            args: Command line arguments
            reporters: List of reporting objects (CSV, JSON, etc.)
        """
        self.args = args
        self.reporters = reporters or []
        self.predictor = None

        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä
        if args.ml:
            self.predictor = self._initialize_predictor()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞, –µ—Å–ª–∏ –æ–Ω–∏ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è
        self.resize_fn = None
        self.resize_fn_upscale = None
        if not args.ml:
            try:
                self.resize_fn = get_resize_function(args.interpolation)
                self.resize_fn_upscale = get_resize_function(INTERPOLATION_METHOD_UPSCALE)
            except ValueError as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–µ—Å–∞–π–∑–∞: {e}")
                raise

    def _initialize_predictor(self) -> Optional[QuickPredictor]:
        """Initializes and configures the predictor for ML predictions."""
        predictor = QuickPredictor()
        predictor.set_mode(self.args.channels)
        if not predictor.load():
            logging.info(_("ML model not found, the actual metrics will be calculated."))
            return None
        return predictor

    def analyze_files(self, files: list[str]) -> None:
        """
        Analyzes a list of files.

        Args:
            files: List of file paths to analyze
        """
        if self.args.no_parallel:
            self._analyze_files_sequential(files)
        else:
            self._analyze_files_parallel(files)

    def _analyze_files_sequential(self, files: list[str]) -> None:
        """Sequential file analysis."""
        from tqdm import tqdm
        for file_path in tqdm(files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤", leave=False):
            try:
                results, meta = self.analyze_file(file_path)
                if results:
                    self._report_results(file_path, results, meta)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
                logging.debug("–î–µ—Ç–∞–ª–∏:", exc_info=True)

    def _analyze_files_parallel(self, files: list[str]) -> None:
        """Parallel file analysis using ProcessPoolExecutor."""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏
        args_dict = vars(self.args)

        with concurrent.futures.ProcessPoolExecutor(max_workers=self.args.threads) as executor:
            future_to_file = {
                executor.submit(process_file_for_analyzer, args_dict, file_path): file_path
                for file_path in files
            }

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            from tqdm import tqdm
            for future in tqdm(concurrent.futures.as_completed(future_to_file),
                               total=len(files), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤", leave=False):
                file_path = future_to_file[future]
                try:
                    results, meta = future.result()
                    if results:
                        self._report_results(file_path, results, meta)
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è {file_path}: {e}")

    def analyze_file(self, file_path: str) -> Tuple[Optional[list], Optional[dict]]:
        """
        Analyzes a single image.

        Args:
            file_path: Path to the image file

        Returns:
            Tuple (results, metadata) or (None, None) in case of error
        """
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_load_result = load_image(file_path)
            if image_load_result.error or image_load_result.data is None:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {file_path}: {image_load_result.error}")
                return None, None

            img_original = image_load_result.data
            max_val = image_load_result.max_value
            channels = image_load_result.channels
            height, width = img_original.shape[:2]

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            if height < self.args.min_size or width < self.args.min_size:
                logging.info(
                    f"–ü—Ä–æ–ø—É—Å–∫ {file_path} (—Ä–∞–∑–º–µ—Ä {width}x{height}) - –º–µ–Ω—å—à–µ, —á–µ–º min_size = {self.args.min_size}")
                return None, None

            # –ù–∞—á–∏–Ω–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
            results = [self._create_original_entry(width, height, channels)]

            # –í—ã—á–∏—Å–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            resolutions = compute_resolutions(width, height, self.args.min_size)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
            for (w, h) in resolutions:
                if w == width and h == height:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
                    continue

                # –ê–Ω–∞–ª–∏–∑ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ (–Ω–µ ML)
                if not self.predictor:
                    results_entry = self._analyze_resize_real(img_original, max_val, channels, w, h, width, height,
                                                              file_path)
                # –ê–Ω–∞–ª–∏–∑ —Å ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º
                else:
                    results_entry = self._analyze_resize_ml(img_original, channels, w, h, width, height)

                results.append(results_entry)

            return results, {'max_val': max_val, 'channels': channels}

        except MemoryError:
            logging.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}")
            return None, None
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            logging.debug("–î–µ—Ç–∞–ª–∏:", exc_info=True)
            return None, None

    def _analyze_resize_real(self, img_original, max_val, channels, w, h, orig_width, orig_height, file_path):
        """Analyzes resize with real metrics calculation."""
        # –£–º–µ–Ω—å—à–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_downscaled = self.resize_fn(img_original, w, h)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.args.save_im_down:
            self._save_intermediate(img_downscaled, file_path, w, h,
                                    InterpolationMethods(self.args.interpolation), '')

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º
        img_upscaled = self.resize_fn_upscale(img_downscaled, orig_width, orig_height)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.args.save_im_up:
            self._save_intermediate(img_upscaled, file_path, w, h,
                                    InterpolationMethods(self.args.interpolation), 'upscaled')

        if self.args.channels: # –ü–æ–∫–∞–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            channels_metrics = calculate_metrics(
                QualityMetrics(self.args.metric),
                img_original, img_upscaled, max_val,
                channels, no_gpu=self.args.no_gpu
            )
            channels_metrics = postprocess_metric_value(channels_metrics, self.args.metric)
            min_metric = min(channels_metrics.values())
            hint = QualityHelper.get_hint(min_metric, QualityMetrics(self.args.metric))
            return f"{w}x{h}", channels_metrics, min_metric, hint
        else:
            metric_value = calculate_metrics(
                QualityMetrics(self.args.metric),
                img_original, img_upscaled, max_val,
                no_gpu=self.args.no_gpu
            )
            metric_value = postprocess_metric_value(metric_value, self.args.metric)
            hint = QualityHelper.get_hint(metric_value, QualityMetrics(self.args.metric))
            return f"{w}x{h}", metric_value, hint

    def _analyze_resize_ml(self, img_original, channels, w, h, orig_width, orig_height):
        """Analyzes resize using ML prediction."""
        if self.args.channels: # –ü–æ–∫–∞–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            channels_metrics = {}
            for c in channels:
                features = extract_features_of_original_img(img_original[..., channels.index(c)])
                features.update({
                    'scale_factor': (w / orig_width + h / orig_height) / 2,
                    'original_width': orig_width,
                    'original_height': orig_height,
                    'channel': c,
                    'method': self.args.interpolation,
                })
                prediction = self.predictor.predict(features)
                val = prediction.get(self.args.metric.value, 0.0)
                channels_metrics[c] = postprocess_metric_value(val, self.args.metric)

            min_metric = min(channels_metrics.values())
            hint = QualityHelper.get_hint(min_metric, QualityMetrics(self.args.metric))
            return f"{w}x{h}", channels_metrics, min_metric, hint
        else:
            # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑
            features = extract_features_of_original_img(img_original)
            features.update({
                'scale_factor': (w / orig_width + h / orig_height) / 2,
                'original_width': orig_width,
                'original_height': orig_height,
                'method': self.args.interpolation,
                'channel': 'combined'
            })
            prediction = self.predictor.predict(features)
            metric_value = prediction.get(self.args.metric.value, 0.0)
            metric_value = postprocess_metric_value(metric_value, self.args.metric)
            hint = QualityHelper.get_hint(metric_value, QualityMetrics(self.args.metric))
            return f"{w}x{h}", metric_value, hint

    def _create_original_entry(self, width, height, channels):
        """Creates an entry for the original image."""
        base_entry = (f"{width}x{height}",)
        channel_value = float('inf') if self.args.metric == QualityMetrics.PSNR else float(1.0)
        if self.args.channels and channels:
            return *base_entry, {c: channel_value for c in channels}, channel_value, "–û—Ä–∏–≥–∏–Ω–∞–ª"
        return *base_entry, channel_value, "–û—Ä–∏–≥–∏–Ω–∞–ª"

    def _report_results(self, file_path, results, meta):
        """Outputs and saves analysis results."""
        # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        ConsoleReporter.print_file_header(file_path, QualityMetrics(self.args.metric))
        if meta['max_val'] < 0.001:
            logging.warning(f"–ù–∏–∑–∫–æ–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {meta['max_val']:.3e}")
        ConsoleReporter.print_quality_table(
            results, self.args.channels, meta.get('channels'),
            QualityMetrics(self.args.metric)
        )

        # –°–æ–∑–¥–∞—ë–º –≥—Ä–∞—Ñ–∏–∫, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if hasattr(self.args, 'chart') and self.args.chart:
            chart_path = self.generate_chart(file_path, results, meta)
            if chart_path:
                try:
                    from rich.console import Console
                    from rich.text import Text
                    Console().print(
                        Text("üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: ", style="bold green") +
                        Text(f"{chart_path}", style="underline blue")
                    )
                except ImportError:
                    from rich.console import Console
                    from rich.text import Text
                    print(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {chart_path}")

        # –ó–∞–ø–∏—Å—å –≤ —Ä–µ–ø–æ—Ä—Ç–µ—Ä—ã
        for rep in self.reporters:
            rep.write_results(os.path.basename(file_path), results, self.args.channels)

    @staticmethod
    def _save_intermediate(img_array, file_path, width, height, interpolation, suffix):
        """Saves intermediate result as PNG."""
        file_path_dir = INTERMEDIATE_DIR
        if not os.path.exists(file_path_dir):
            os.makedirs(file_path_dir, exist_ok=True)

        output_filename = (
                os.path.splitext(os.path.basename(file_path))[0] +
                f"_({interpolation.value}_{width}x{height}){'_' + suffix if suffix else ''}.png"
        )
        output_path = os.path.join(file_path_dir, output_filename)

        arr_for_save = img_array
        if arr_for_save.ndim == 3 and arr_for_save.shape[2] == 1:
            arr_for_save = arr_for_save.squeeze(axis=-1)

        arr_uint8 = np.clip(arr_for_save * 255.0, 0, 255).astype(np.uint8)

        pil_img = Image.fromarray(arr_uint8)
        pil_img.save(output_path, format="PNG", optimize=True)


    def generate_chart(self, file_path: str, results: list, meta: dict) -> Optional[str]:
        """
        Generates a chart showing quality dependency on resolution.

        Args:
            file_path: Path to the image file
            results: Quality analysis results
            meta: Image metadata

        Returns:
            Path to the created chart or None
        """
        if not self.args.chart:
            return None

        try:
            from ..utils.visualization import generate_quality_chart, get_chart_filename

            file_basename = os.path.basename(file_path)
            chart_path = get_chart_filename(
                os.path.splitext(file_basename)[0],
                QualityMetrics(self.args.metric),
                self.args.channels
            )

            title = f"–ö–∞—á–µ—Å—Ç–≤–æ ({self.args.metric.upper()}) –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è\n{file_basename}"

            chart_file = generate_quality_chart(
                results,
                chart_path,
                title=title,
                metric_type=QualityMetrics(self.args.metric),
                analyze_channels=self.args.channels,
                channels=meta.get('channels')
            )

            logging.debug(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {chart_file}")
            return chart_file
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
            logging.debug("–î–µ—Ç–∞–ª–∏:", exc_info=True)
            return None


def process_file_for_analyzer(args_dict, file_path):
    """
    Wrapper function for processing a file in a separate process.

    Args:
        args_dict: Dictionary with arguments for creating ImageAnalyzer
        file_path: Path to the file for analysis
    """
    try:
        # –°–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–∑ —Å–ª–æ–≤–∞—Ä—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        args = argparse.Namespace(**args_dict)
        analyzer = ImageAnalyzer(args)
        return analyzer.analyze_file(file_path)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        logging.debug("–î–µ—Ç–∞–ª–∏:", exc_info=True)
        return None, None


def postprocess_metric_value(metric_value, metric_type):
    """
    Method for postprocessing metric value.
    """
    # –î–ª—è —Å–ª–æ–≤–∞—Ä—è (–ø–æ–∫–∞–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
    if isinstance(metric_value, dict):
        if QualityMetrics(metric_type) == QualityMetrics.PSNR:
            return {channel: float('inf') if value >= PSNR_IS_LARGE_AS_INF else value
                    for channel, value in metric_value.items()}
        else:
            # –ö–ª–µ–º–ø–∏–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0;1] –¥–ª—è –Ω–µ-PSNR –º–µ—Ç—Ä–∏–∫
            return {channel: max(0.0, min(1.0, value))
                    for channel, value in metric_value.items()}

    # –î–ª—è —Å–∫–∞–ª—è—Ä–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
    if isinstance(metric_value, (int, float, np.number)):
        if QualityMetrics(metric_type) == QualityMetrics.PSNR:
            if metric_value >= PSNR_IS_LARGE_AS_INF:
                return float('inf')
            return metric_value
        else:
            # –ö–ª–µ–º–ø–∏–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0;1] –¥–ª—è –Ω–µ-PSNR –º–µ—Ç—Ä–∏–∫
            return max(0.0, min(1.0, metric_value))

    # –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
    raise TypeError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —á–∏—Å–ª–æ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å, –ø–æ–ª—É—á–µ–Ω–æ: {type(metric_value).__name__}")